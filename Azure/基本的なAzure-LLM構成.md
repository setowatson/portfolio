# Azureサービスを活用した基本的なLLM構成

社内のマニュアルやドキュメントを活用し、AzureサービスでLLM（Large Language Model）を構成する基本的な方法について解説します。

## 使用する主なAzureサービス

### Azure OpenAI Service
Azure OpenAI Serviceは、GPTシリーズのLLMを活用できるサービスです。
- **特徴**
  - 強力な自然言語処理能力を活用。
  - 他のAzureサービスとの統合が容易。
- **活用例**
  - ドキュメントの内容を基に、問い合わせへの回答を生成。
  - ユーザーが曖昧な質問をした際のコンテキスト理解。

### Azure Cognitive Search
Azure Cognitive Searchは、高度な全文検索機能を提供します。
- **特徴**
  - ドキュメントやデータをインデックス化して検索可能に。
  - AIによる強化検索（AIエンリッチメント機能）をサポート。
- **活用例**
  - 社内マニュアルやFAQをインデックス化。
  - ユーザーのクエリに関連するドキュメントを迅速に検索。

### Azure Blob Storage
Azure Blob Storageは、構造化・非構造化データを安全に保存するためのストレージサービスです。
- **特徴**
  - マニュアルやPDFファイルなどの大容量データを保存可能。
  - Cognitive SearchやAIモデルで利用可能な形式に対応。
- **活用例**
  - 社内ドキュメントの格納場所として利用。
  - データの分類やアクセス制限を適用。

### Azure Functions
Azure Functionsは、イベント駆動型のサーバーレス計算を可能にします。
- **特徴**
  - トリガーイベントに応じてコードを実行。
  - 軽量かつスケーラブル。
- **活用例**
  - ドキュメントがアップロードされた際に、自動的にインデックス化を実行。
  - 外部システムからのAPIリクエストを処理。

### Azure Monitor
Azure Monitorは、システムのパフォーマンス監視やログ管理を支援します。
- **特徴**
  - ボットや検索サービスの稼働状況をリアルタイムで監視。
  - トラブルシューティングやパフォーマンスの最適化に役立つ。
- **活用例**
  - RAG構成の稼働状況の可視化。
  - エラー検知やボトルネック解消。


## めちゃくちゃ優しい言い換え


LLMを「知識という名の素材の味が染み込んだスープ」だとします。

このスープを作るために使うAzureサービスを、それぞれ一言ずつで表すと以下のように例えられるかもしれません。

Azure OpenAI Service: スープの出汁
Azure Cognitive Search: 材料を選別するシェフ
Azure Blob Storage: 食材をたくさん保存する冷蔵庫
Azure Functions: 自動で動く調理器具（シェフは具材を選ぶだけ）
Azure Monitor: スープの味見役
これらが連携して、最高のスープ（回答）を作り出します！

## 補足：RAG構成の流れ

1. **データの収集**
   - Azure Blob Storageに社内マニュアルやドキュメントをアップロード。
   - ドキュメント形式：PDF、Word、テキスト、HTMLなど。

2. **データのインデックス化**
   - Azure Cognitive Searchでアップロードされたデータをインデックス化。
   - メタデータを追加して検索精度を向上。

3. **ユーザークエリ処理**
   - ユーザーが入力した質問をAzure OpenAI Serviceで解析。
   - 解析結果を基に、Azure Cognitive Searchで関連するドキュメントを検索。

4. **回答生成**
   - 検索されたドキュメント内容をLLMに入力し、最適な回答を生成。
   - 回答内容を整形してユーザーに提供。


AzureのRAG構成については、また別の記事にします。

<img width="701" alt="image" src="https://github.com/user-attachments/assets/5cf1b7c8-a6e9-45fd-ac7f-614bdea7d9d5" />

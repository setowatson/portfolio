
# 1.本投稿の概要

## 1.1 目的・前置き

- 本記事の目的
    - 自分の学びの整理＆アウトプットするため。
    - 今後Dataikuを使用しようと思った人の役に立ちたいため。


今回初めてDataikuを使ったのですが、総合的にとても魅力的でした。
機会があればぜひ今後も使いたいと思っているのですが、
私は決してDataikuの回しもんではないですし関係者でもありません。

また、私の本業もエンジニアではありません。
Pythonを少しだけ触れる・基本情報を持っているくらいのITレベルで、今回興味本位でRAG作成に向けてのGUIツールを触ってみています。

そんな自分だからこそ今回できたことや学んだこと・難しかったことを書く価値があると思い、書いています。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/7ee472ea-65a9-70bc-af9e-6c29588ae67f.png)

ちょっとついっ⚪︎ー感ある。


## 1.2 本投稿で書いていること

- Dataikuがどんなものかのざっくりした概要
- 基本的なRAGを作成するまでの経緯（ノーコード＋αの範囲）
- 公式には書いていない小さな躓きポイント
- 以上を踏まえた個人(非エンジニア)の感想

## 1.3 本投稿に書いていないこと

- Dataikuの具体的なレシピの使用方法・コーディング
- Dataikuの法人で活用する方法・RAG以外の活用方法
- コンペで勝つ方法


## 1.4 使用したコンペ

以下のSIGNATEのコンペに参加した際にDataikuを使用しました。
本投稿でコンペ内容については詳しく取り扱いませんので、気になる方は以下をご覧ください。

https://signate.jp/competitions/1515

以下、原文まま。


> ⚫︎課題
本コンペティションでは、J-LAKE(*パートナー企業であるDATAZORAのKIJIサービス提供データを含む)の情報を用いてRAGシステムを構築していただきます。提供されたデータを元に、質問（query.csv）に対する回答を生成し、その回答の精度を競います。 生成した回答は、指定のフォーマットに従い、投稿してください。

PDFデータと質問リストをいただくので、その質問リストにいかに正確に回答を与えられるかというコンペです。



今回私はコンペの入賞を狙ってチャレンジしたわけではないです(そもそもそんなレベルではない)が、
コンペ上位者のコードやブログはめちゃくちゃ楽しみです。私に理解できるかわかりませんが…。


# 2. 使用したGUIツール「Dataiku」について

## 2.1 概要


Dataikuとは、データサイエンスや機械学習モデルの開発を効率化するためのプラットフォームです。ノーコード/ローコードでデータの準備・可視化・モデリング・デプロイまでを一元的に管理でき、企業のデータ分析チームが協力して作業しやすいよう設計されています。


<br> 以下、公式ホームページ。フランスで設立された企業なんですね。

https://www.dataiku.com/ja/


ダウンロードはこちらから。
インストール版とクラウド版がありますが、私はインストールしています。

https://www.dataiku.com/ja/%E8%A3%BD%E5%93%81/%E5%90%84%E7%A8%AE%E3%83%97%E3%83%A9%E3%83%B3%E3%81%A8%E6%A9%9F%E8%83%BD/#


Qiita公式アカウントもあります。生成AI活用関連の学びをたくさん投稿してくれています。

https://qiita.com/Dataiku

↓個人的にはこの投稿が好きでした。学生マインド忘れないようにしよう。

> 学生マインドの育成
この日の最も力強いテーマのひとつは、組織内で「学生マインドセット」を維持することの重要性といえるでしょう。AIが進化し続けるにつれて、AIに携わる人々も進化し続けなければなりません。AI分野で成功するためには、継続的な学習と新しいアイデアに対するオープンな姿勢が欠かせないのです。
このマインドセットとは、単に技術的な知識を習得することではなく、コラボレーション、柔軟性、誠実さの文化を醸成することです。リーダーはフィードバックを受け入れ、同僚や従業員、さらにはAIそのものから学ぶことで自分の視点を変えようとする姿勢が必要です。

https://qiita.com/Dataiku/items/e4742766349c3d1afb1d#%E5%AD%A6%E7%94%9F%E3%83%9E%E3%82%A4%E3%83%B3%E3%83%89%E3%81%AE%E8%82%B2%E6%88%90



## 2.2 主な機能

### (1) GUIベースのデータ処理

SQLやPythonを使わなくても、データの前処理や変換が可能です。
もちろんシステムにこだわる程コーディングが必要になりますが、ざっくりとした流れだけであればノーコードで実行できます。
今回もテキストを文字にするOCRの工程はdataiku内の機能で行っています。
ここは今回めちゃくちゃいいなと思ったので、下でも記載します、

### (2) 機械学習モデルの作成

ノーコード/ローコードで機械学習モデルをトレーニング・評価できます。
今回は言語タスクのなかでの生成AI活用だったので、こちらに機械学習モデルを使用した感はあまりありませんが、企業事例を見るとマーケや研究分野分野でもよく使われているようです。

### (3) フロー・パイプライン管理

データ処理やモデル学習のフローを定義し、実行できます。
このフローをいじる感覚は直感的でわかりやすく、私にとってもとても楽しかったです。


### (4) APIの接続

dataiku内の環境設定では、各種APIとの接続も簡単に行えます。
今回のコンペではMicrosoftのAzure OpenAIのAPIが一時的に付与されていたので、それを接続しました。ほかにもOpenAIやAWS、Snowflakesと接続ができるようです。


## 2.3 本コンペでdataikuを使用した理由

正直に言うとこれはツール云々ではなく、**「サポートが手厚そうだったから」** です。


今回コンペ用のSlackチャンネルがあり、その中ではいろんな方がコンペの質問やRAG構築に関する相談を投稿しています。
最初に情報収集がてらざーっと見ていたのですが、dataikuの質問チャンネルがまあ平和で優しそうだなと言う印象がありました。そのほかにも色々と使用ツールとそれに応じたチャネルがあるのですが、決して他を批判しているわけではないです。主観です。

私は自分で１からRAGを作成するのは初めてだったので、GUIツールという点やノーコードでできる点にはもちろん惹かれましたが、サポート体制が手厚いことは決めてになる十分な魅力でした。

あくまでコンペ内の話ですし、もしかしたら担当の方が属人的にめちゃくちゃいい方だったという可能性もありますが、実際の製品導入の際のサポートも安心できるのではと思わされました。




# 3. 本コンペで作成したもの




## 3.1 完全ノーコードver

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/511bbd25-fb7a-76ab-df4c-61bd60b3532f.png)

真ん中の「aI」部分がプロンプト作成やLLM機能を設定する箇所です。
- query：コンペ指定の質問リスト
- document_text：PDFデータをテキスト化したもの(OCR)
- documents_text_embedded：テキストデータをベクトル化したKnowledge Bank
- query_generated：質問リストqueryファイルとLLMによる回答をマージしたファイル
- query_generated_prepared：コンペ提出に向けて整理したファイル

本当は質疑応答の感じも載せたいのですが、コンペのルールにどれくらい引っ掛かるのか読めないので、一旦今回はフローのみ共有します。

## 3.2 チャンク化をPythonで実行


![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/c8a1ce28-4231-3770-0d2e-a9ee90ef9069.png)

OCR化した後、チャンク分割のみコードレシピで行い、後続のベクトルDB構築はビジュアルレシピを利用しています。黄色のフローがPython実行部分です。
今回のOCRした結果のテキストにはかなり大小差がありました。そのため、チャンクの長さやオーバーヘッドを手動で何度か実行しながら調整しました。
最終的に調整した結果が以下。

```ruby:チャンク数の統計
総チャンク数: 2133

チャンクの長さの統計:
count    2133.000000
mean      836.610877
std       294.134557
min       300.000000
25%       676.000000
50%       913.000000
75%       968.000000
max      4426.000000
Name: chunk_length, dtype: float64
2133 rows successfully written (PFFdmZeYJM)
```

## 3.3 ハイブリッドサーチを利用

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/856b3b03-8716-ba1f-40ed-c5eecc64a75f.png)

実はこちらのフローはエラーが消えず完成していないフローです。
本記事を書いている最中も色々試行錯誤しているのですが、先にコンペが終わってしまう気がしたので、一旦ここまでを成果として載せています。
「意味的な類似性」と「キーワードの一致」の両方を考慮することで、より良い検索結果を得ることができるという考え方で精度をあげようとしていたのですが、現時点の私の知識では実装まで至りませんでした。悔しい。


# 4. dataikuを使用した感想

## 4.1 感動したこと


### (1) わかりやすいGUI

もうこれに尽きますね。


今回ここまで成功したり失敗したりと触って進めることができた要因は様々ありますが、とにかくGUIベースの設計がわかりやすいという点です。

例えば「document_text2」というファイル(PDFをOCR化したファイル)を選択すると、横にこのようなパネルが表示されます。
ここにdocument_text2にできる操作がだいたい揃っています。
今回私はLLMレシピやPythonを中心に選択していましたが、他にも回帰予測やクラスタリングなどの機械学習モデルの選択があります。Kaggleコンペもdaitaikuでチャレンジできる気がしますね。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/2a4a05b0-101b-d71d-9f6a-ea57dfb7404b.png)


もちろんコーディングが必要な場面は自ずと出てきますが、そこは役割分担かと思います。ただ同じことをCLIで行う場合、エンジニアと非エンジニア(もしくはバイヤーとベンダー)の境界はもっとはっきりしたものになってしまいます。
非エンジニアでもここまで設計の思考・アクションができることにより、それぞれの共同思考部分が増えるのは、組織にとってもいいことな気がします。

### (2) プラグインが超優秀

上のように機械学習を実装するための基本的な操作はデフォルトで搭載されているのですが、さらにこの実装機能を拡張するためdataikuではプラグインやコードサンプルがたくさんあります。
インストールを行えば、上に書いているパネルにアクションが表示されるので、簡単に利用できます。

↓プラグインをインストールする画面。156個あるらしい。


![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/a3e9dc22-e5f3-54c0-bd11-d4b361da3770.png)

↓個人的に次はこのへんをdataikuで使ってみたい。バージョン管理とか整合性取るのが少し難しくなるかもしれない。対策はあると思いますが。
![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/35359995-58be-21b4-aa22-6dd950e26ae4.png)


今回のRAG作成では、「Text extraction and OCR」というプラグインを使用しています。
↓以下、公式ドキュメント。

https://www.dataiku.com/product/plugins/tesseract-ocr/

例えば、以下のIPAが出しているPDFファイルを参考に記載してみます。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/1943de0b-7ec5-7d85-32b3-a5e8d219ffc2.png)
引用；https://www.ipa.go.jp/security/10threats/10threats2024.html

↓

```ruby:OCR結果

「情報セキュリティ10大脅威」とは？
 IPAが2006年から毎年発行している資料
 前年に発生したセキュリティ事故や攻撃の状況等から
IPAが脅威候補を選出
 セキュリティ専門家や企業のシステム担当等から 
構成される「10大脅威選考会」が投票
 TOP10入りした脅威を「10大脅威」として 
脅威の概要、被害事例、対策方法等を解説
Copyright © 2024 独立行政法人情報処理推進機構
2
10大脅威の特徴
脅威に対して様々な立場の方が存在
 立場ごとに注意すべき脅威も異なるはず
 家庭等でパソコンやスマホを利用する人 「個人」
「組織」 
 企業や政府機関等の組織
 組織のシステム管理者や社員・職員
「個人」と「組織」の２つの立場で脅威を解説
Copyright © 2024 独立行政法人情報処理推進機構
3
```


と、こんな感じです。
もちろんこれだけでは上手く意味まで読み取れていないことがわかると思いますが、こうしたプラグインが簡単に使用できます。


### (3) 公式サンプルをさんこうできる

以下開いていただくとわかるのですが、サンプルフローがたくさん用意されています。
どんなプラグインやコーディングを使用しているかまで見れるため、似たようなモデルを探せばデータ構造を合わせるだけでフローを真似することができます。

↓サンプルリスト　日本語対応のものもありますね。

https://gallery.dataiku.com/project-list/

今回、私は以下のサンプルをかなり参考にしました。RAGの基本構造はもちろんですが、精度を上げるためのハイブリッドサーチやプロンプトエンジニアリングのサンプルがあります。
私がコーディングに慣れていないため自分のデータと合わせることや環境設定に時間がかかりましたが、みているだけでも面白いです。

↓Advanced RAGサンプルフロー

https://gallery.dataiku.com/projects/EX_ADVANCED_RAG/flow/



## 4.2 難しかったこと・躓いたポイント

※ここで書いているのはかなり初歩的なミスや躓きだと思います。
だからこそあまり載っていないのですが…。

### (1) 最初のPython環境設定


IT初心者の似た立場の方ならわかると思うのですが、何かをやろうとしてもそこまで辿り着けないという経験ありませんか？そもそも失敗ですらない的な…。

今回のdataikuでも私が1番時間を最初の環境設定かけたのはここかもしれません。
本来以下のようにスムーズにPython環境を構築できるのですが、Pythonが正しいバージョンではなかったり、正しいPATHにPythonが存在しないとエラーが起きます。


![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/4e3f0517-286e-eadd-9629-17decefad50e.png)

上の時点で「environment creation failed」とか「not available」と出る方はこの対象だと思います。
Pythonを使用可能なバージョンにアップグレード(ダウングレード)するだけならすぐ可能と思いますが、私はPythonのPATHが迷子になっておりその解消に大変苦労しました。dataikuもはや関係ないです。
以下記事に私のPythonPATH迷子エラーの解消方法をまとめているので、もし同じかもという方は役に立つかもしれません。


https://qiita.com/setowatson/items/7f456405d6caab57beb2

### (2) コーディング時に使用できないライブラリがある際の対応

上に書いている通り、基本のRAGをノーコードで作成した後いくつかPythonでの手動の作成にも取り組んでいるのですが、まあエラーが多くあり…。解消に向けたヒント表示などもないので、初心者にとっては少し難しかったです。
Colabやmacだったらインストールで済むところ、仮想環境のためどこで何が不足しているのかがいまいちわからないことも多くありました。

とりあえずすぐ確認できるのは、
- **正しい環境を選び直す**
- **パッケージを更新する**
- **環境を再構築する**
の3つがあるかと思います。

↓Pythonの実行環境を作成した環境にできているか。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/61310a58-fd1d-9ba0-aba0-7bb7aeead4ec.png)

↓ Code Envs画面にて、インストールされたパッケージを確認する。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/8669129c-8b82-9335-2d56-acce36219025.png)


# 5. まとめ

## 5.1 私から見える「dataikuはこんな方に使って欲しい！」

- **RAGを個人で作ってみたい**
- **RAGの構築システムを勉強したい**

今回私は自分のインプットのためかつ営利目的ではないため気楽に使用しましたが、
同じような立場の方ってこの時代多いのではないでしょうか？
全然関係ない職種や業界の企業のなかでもアンテナを立てている方だったり、これから社会に出る学生さんだったり、上から言われて生成AIの導入を検討しなきゃいけない情シスの方だったり。

そんな方達にとってはdataikuは大変敷居の低いGUIツールになっていると思います。
もちろん「RAGとは何か」とか「どんなデータが検索されやすいのか」など、生成AIを活用する上でのある程度の知識は必要ですが、同時にやっていくうちにわかるものもあると思っています。

私が作成したRAGフローもdataikuを触ったことのない方は難しそうに見えるかもしれませんが、ほとんどは公式の説明を見ながら、見よう見まねで半日程度かけて作成したものです(そのうち半分は環境構築笑)。
少しでもかっこいいなとか触ってみたいと思ったらぜひチャレンジしてみてください。
書いていませんでしたが無料で使用できます。
API接続をする場合そこでお金がかかりますが、無料の範囲でも十分学べること・健闘できることがあると思います。

おすすめの順番は、 **「1.基本のRAG構築」→「2.データの整備」→「3.RAGの精度向上」** の順でチャレンジしてみることです。
まずどんなAI活用でもそうですが、データが綺麗であることに越したことはありません。OCR機能や前処理ができる機能も搭載していますが、ここはdataiku前でやるほうが現実的な気がします。
オブジェクトの除去や表の正規化などの前処理など事前に綺麗にできるものがあればしておきましょう。


## 5.2 今後やっていきたいこと

KaggleやSIGNATEの他のコンペでも使用してみたいですね！
特にビッグデータの定量分析や参照データが複数あるコンペなどには、楽に効率化を目指せそう。
Pythonの実行環境設定やライブラリの操作などはもう少し慣れが必要な気がするので、ノーコードでできることはノーコードで実施しつつ、甘えすぎずに、スコア向上の余地がありそうであれば積極的にコーディングを使っていきたいと思います


## 5.3 補足：今回のRAG作成で特に参考にしたサイト

### (1) RAGを作るまでの基本 @fumihiko_kimura

今回のコンペ専用の手引書として投稿してくださっていますが、コンペ関係なくDataikuでLLMを作る時の基本として役に立つと思います。


https://qiita.com/fumihiko_kimura/items/bdb889de49b1f863904f

### (2) 基本のRAGができてから次に見るもの @TsuyoshiK7 

RAGの精度を上げるためにコーディングを加えようとした場合、参考になると思います。

https://qiita.com/TsuyoshiK7/items/f8703d2398ba1dbed806


### (3) 公式サンプル Advanced RAG

上でも書いていますが、大変参考にさせていただきました。
真似できるところがたくさんあります。


https://gallery.dataiku.com/projects/EX_ADVANCED_RAG/flow/